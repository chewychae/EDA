{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f801ffb4-9a94-415a-a8cc-fbdd7b076d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.Requirement already satisfied: imbalanced-learn in c:\\users\\acer\\anaconda3\\envs\\eda310\\lib\\site-packages (0.11.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\acer\\anaconda3\\envs\\eda310\\lib\\site-packages (from imbalanced-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\acer\\anaconda3\\envs\\eda310\\lib\\site-packages (from imbalanced-learn) (1.15.2)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\acer\\anaconda3\\envs\\eda310\\lib\\site-packages (from imbalanced-learn) (1.3.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\acer\\anaconda3\\envs\\eda310\\lib\\site-packages (from imbalanced-learn) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\acer\\anaconda3\\envs\\eda310\\lib\\site-packages (from imbalanced-learn) (3.6.0)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install imbalanced-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2b62490-c7e6-45a6-96c8-ccc7b95ad036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class distribution:\n",
      "Class\n",
      "1    8028\n",
      "0    3808\n",
      "2    3370\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Balanced class distribution:\n",
      "Class\n",
      "0    8028\n",
      "1    8028\n",
      "2    8028\n",
      "Name: count, dtype: int64\n",
      "\n",
      "‚úÖ Balanced dataset saved to:\n",
      "C:\\Users\\Acer\\Downloads\\FINAL PROJECT\\reduced_features_SMOTE_8028.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import os\n",
    "\n",
    "# Load dataset\n",
    "input_path = r\"C:\\Users\\Acer\\Downloads\\FINAL PROJECT\\reduced_features.csv\"\n",
    "df = pd.read_csv(input_path)\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop(columns=['Class'])\n",
    "y = df['Class']\n",
    "\n",
    "# Show original distribution\n",
    "print(\"Original class distribution:\")\n",
    "print(y.value_counts())\n",
    "\n",
    "# SMOTE strategy: all classes ‚Üí 8028\n",
    "sampling_strategy = {cls: 8028 for cls in y.unique()}\n",
    "\n",
    "smote = SMOTE(\n",
    "    sampling_strategy=sampling_strategy,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Apply SMOTE\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Recombine into DataFrame\n",
    "df_balanced = pd.concat(\n",
    "    [\n",
    "        pd.DataFrame(X_resampled, columns=X.columns),\n",
    "        pd.Series(y_resampled, name='Class')\n",
    "    ],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Output path\n",
    "output_path = r\"C:\\Users\\Acer\\Downloads\\FINAL PROJECT\\reduced_features_SMOTE_8028.csv\"\n",
    "\n",
    "# Save file\n",
    "df_balanced.to_csv(output_path, index=False)\n",
    "\n",
    "# Show new distribution\n",
    "print(\"\\nBalanced class distribution:\")\n",
    "print(df_balanced['Class'].value_counts())\n",
    "\n",
    "print(f\"\\n‚úÖ Balanced dataset saved to:\\n{output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b1d09f8-e57e-4a6c-bb59-7fef2ecc4449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STEP 2 ‚Äî DATA CLEANING & PREPARATION\n",
      "================================================================================\n",
      "\n",
      "Dataset loaded successfully.\n",
      "Initial dataset shape: (24084, 6)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1. MISSING VALUES CHECK\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Missing values BEFORE cleaning:\n",
      "R              0\n",
      "H_hsv          0\n",
      "Contrast       0\n",
      "Correlation    0\n",
      "Energy         0\n",
      "Class          0\n",
      "dtype: int64\n",
      "\n",
      "Missing values AFTER cleaning:\n",
      "R              0\n",
      "H_hsv          0\n",
      "Contrast       0\n",
      "Correlation    0\n",
      "Energy         0\n",
      "Class          0\n",
      "dtype: int64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2. DUPLICATE RECORDS CHECK\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Duplicate rows BEFORE removal: 5\n",
      "Duplicate rows AFTER removal: 0\n",
      "\n",
      "Dataset shape after duplicate removal: (24079, 6)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3. VARIABLE TYPE VERIFICATION\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Data types of variables:\n",
      "R              float64\n",
      "H_hsv          float64\n",
      "Contrast       float64\n",
      "Correlation    float64\n",
      "Energy         float64\n",
      "Class            int64\n",
      "dtype: object\n",
      "\n",
      "Updated data types:\n",
      "R               float64\n",
      "H_hsv           float64\n",
      "Contrast        float64\n",
      "Correlation     float64\n",
      "Energy          float64\n",
      "Class          category\n",
      "dtype: object\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4. NEW VARIABLE CREATION\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "No new variables were created.\n",
      "Existing feature set is sufficient after feature reduction.\n",
      "\n",
      "================================================================================\n",
      "BEFORE & AFTER SUMMARY\n",
      "================================================================================\n",
      "\n",
      "Class distribution AFTER cleaning:\n",
      "Class\n",
      "1    8028\n",
      "2    8028\n",
      "0    8023\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final dataset shape:\n",
      "(24079, 6)\n",
      "\n",
      "STEP 2 COMPLETED SUCCESSFULLY\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"STEP 2 ‚Äî DATA CLEANING & PREPARATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Load SMOTEd dataset\n",
    "# ------------------------------------------------------------------\n",
    "file_path = r\"C:\\Users\\Acer\\Downloads\\FINAL PROJECT\\reduced_features_SMOTE_8028.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "print(\"\\nDataset loaded successfully.\")\n",
    "print(f\"Initial dataset shape: {df.shape}\")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 1. Handling Missing Values\n",
    "# ------------------------------------------------------------------\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"1. MISSING VALUES CHECK\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "missing_before = df.isnull().sum()\n",
    "print(\"\\nMissing values BEFORE cleaning:\")\n",
    "print(missing_before)\n",
    "\n",
    "# No imputation needed (but included for documentation)\n",
    "df_cleaned = df.dropna()\n",
    "\n",
    "missing_after = df_cleaned.isnull().sum()\n",
    "print(\"\\nMissing values AFTER cleaning:\")\n",
    "print(missing_after)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 2. Removal of Duplicates\n",
    "# ------------------------------------------------------------------\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"2. DUPLICATE RECORDS CHECK\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "duplicates_before = df_cleaned.duplicated().sum()\n",
    "print(f\"\\nDuplicate rows BEFORE removal: {duplicates_before}\")\n",
    "\n",
    "df_cleaned = df_cleaned.drop_duplicates()\n",
    "\n",
    "duplicates_after = df_cleaned.duplicated().sum()\n",
    "print(f\"Duplicate rows AFTER removal: {duplicates_after}\")\n",
    "\n",
    "print(f\"\\nDataset shape after duplicate removal: {df_cleaned.shape}\")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 3. Variable Type Adjustments\n",
    "# ------------------------------------------------------------------\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"3. VARIABLE TYPE VERIFICATION\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "print(\"\\nData types of variables:\")\n",
    "print(df_cleaned.dtypes)\n",
    "\n",
    "# Ensure Class is treated as categorical\n",
    "df_cleaned['Class'] = df_cleaned['Class'].astype('category')\n",
    "\n",
    "print(\"\\nUpdated data types:\")\n",
    "print(df_cleaned.dtypes)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 4. Creation of New Variables\n",
    "# ------------------------------------------------------------------\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"4. NEW VARIABLE CREATION\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "print(\"\\nNo new variables were created.\")\n",
    "print(\"Existing feature set is sufficient after feature reduction.\")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# BEFORE & AFTER SUMMARY\n",
    "# ------------------------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BEFORE & AFTER SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nClass distribution AFTER cleaning:\")\n",
    "print(df_cleaned['Class'].value_counts())\n",
    "\n",
    "print(\"\\nFinal dataset shape:\")\n",
    "print(df_cleaned.shape)\n",
    "\n",
    "print(\"\\nSTEP 2 COMPLETED SUCCESSFULLY\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f25f6d10-e692-4430-a39e-7d858946d220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "STEP 3 ‚Äî DESCRIPTIVE STATISTICS (GROUPED BY CLASS)\n",
      "====================================================================================================\n",
      "\n",
      "Class Distribution:\n",
      "Class_Name\n",
      "Underdried         8028\n",
      "Perfectly_Dried    8028\n",
      "Overdried          8028\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Saved descriptive statistics for: Overdried\n",
      "\n",
      "Saved descriptive statistics for: Perfectly_Dried\n",
      "\n",
      "Saved descriptive statistics for: Underdried\n",
      "\n",
      "ALL RESULTS SAVED SUCCESSFULLY\n",
      "üìÅ Location: C:\\Users\\Acer\\Downloads\\FINAL PROJECT\\STEP_3_DESCRIPTIVE_STATISTICS\n",
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# PATH SETUP\n",
    "# ------------------------------------------------------------------\n",
    "base_path = r\"C:\\Users\\Acer\\Downloads\\FINAL PROJECT\"\n",
    "output_folder = os.path.join(base_path, \"STEP_3_DESCRIPTIVE_STATISTICS\")\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "data_path = os.path.join(base_path, \"reduced_features_SMOTE_8028.csv\")\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"STEP 3 ‚Äî DESCRIPTIVE STATISTICS (GROUPED BY CLASS)\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# LOAD DATASET\n",
    "# ------------------------------------------------------------------\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "class_map = {\n",
    "    0: \"Underdried\",\n",
    "    1: \"Perfectly_Dried\",\n",
    "    2: \"Overdried\"\n",
    "}\n",
    "df['Class_Name'] = df['Class'].map(class_map)\n",
    "\n",
    "features = ['R', 'H_hsv', 'Contrast', 'Correlation', 'Energy']\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# FREQUENCY TABLE\n",
    "# ------------------------------------------------------------------\n",
    "freq_table = df['Class_Name'].value_counts()\n",
    "freq_table.to_csv(os.path.join(output_folder, \"frequency_table.csv\"))\n",
    "\n",
    "print(\"\\nClass Distribution:\")\n",
    "print(freq_table)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# DESCRIPTIVE STATISTICS PER CLASS\n",
    "# ------------------------------------------------------------------\n",
    "all_stats = []\n",
    "\n",
    "for cls, group in df.groupby('Class_Name'):\n",
    "    stats = pd.DataFrame(index=features)\n",
    "    stats['Mean'] = group[features].mean()\n",
    "    stats['Median'] = group[features].median()\n",
    "    stats['Mode'] = group[features].mode().iloc[0]\n",
    "    stats['Min'] = group[features].min()\n",
    "    stats['Max'] = group[features].max()\n",
    "    stats['Range'] = stats['Max'] - stats['Min']\n",
    "    stats['Variance'] = group[features].var()\n",
    "    stats['Std_Dev'] = group[features].std()\n",
    "    stats['Q1'] = group[features].quantile(0.25)\n",
    "    stats['Q3'] = group[features].quantile(0.75)\n",
    "    stats['IQR'] = stats['Q3'] - stats['Q1']\n",
    "    stats['Class'] = cls\n",
    "\n",
    "    stats.to_csv(os.path.join(output_folder, f\"descriptive_stats_{cls}.csv\"))\n",
    "    all_stats.append(stats)\n",
    "\n",
    "    print(f\"\\nSaved descriptive statistics for: {cls}\")\n",
    "\n",
    "# Combined summary\n",
    "combined_stats = pd.concat(all_stats)\n",
    "combined_stats.to_csv(os.path.join(output_folder, \"descriptive_stats_ALL_CLASSES.csv\"))\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# HISTOGRAMS\n",
    "# ------------------------------------------------------------------\n",
    "hist_folder = os.path.join(output_folder, \"Histograms\")\n",
    "os.makedirs(hist_folder, exist_ok=True)\n",
    "\n",
    "for feature in features:\n",
    "    plt.figure()\n",
    "    for cls in class_map.values():\n",
    "        plt.hist(\n",
    "            df[df['Class_Name'] == cls][feature],\n",
    "            bins=30,\n",
    "            alpha=0.5,\n",
    "            label=cls\n",
    "        )\n",
    "    plt.title(f\"Histogram of {feature} by Class\")\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(hist_folder, f\"histogram_{feature}.png\"))\n",
    "    plt.close()\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# BOXPLOTS\n",
    "# ------------------------------------------------------------------\n",
    "box_folder = os.path.join(output_folder, \"Boxplots\")\n",
    "os.makedirs(box_folder, exist_ok=True)\n",
    "\n",
    "for feature in features:\n",
    "    plt.figure()\n",
    "    df.boxplot(column=feature, by='Class_Name')\n",
    "    plt.title(f\"Boxplot of {feature} by Class\")\n",
    "    plt.suptitle(\"\")\n",
    "    plt.xlabel(\"Class\")\n",
    "    plt.ylabel(feature)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(box_folder, f\"boxplot_{feature}.png\"))\n",
    "    plt.close()\n",
    "\n",
    "print(\"\\nALL RESULTS SAVED SUCCESSFULLY\")\n",
    "print(f\"üìÅ Location: {output_folder}\")\n",
    "print(\"=\"*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "828475d5-4010-4a37-85db-e98092aa30e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "STEP 4 ‚Äî EXPLORATORY DATA ANALYSIS (EDA)\n",
      "====================================================================================================\n",
      "\n",
      "Generating scatter plots...\n",
      "\n",
      "Computing correlation matrices...\n",
      "\n",
      "Generating clean correlation heatmaps...\n",
      "Clean heatmaps generated successfully.\n",
      "\n",
      "STEP 4 EDA COMPLETED SUCCESSFULLY\n",
      "üìÅ All outputs saved to: C:\\Users\\Acer\\Downloads\\FINAL PROJECT\\STEP_4_EDA\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# PATH SETUP\n",
    "# ------------------------------------------------------------------\n",
    "base_path = r\"C:\\Users\\Acer\\Downloads\\FINAL PROJECT\"\n",
    "output_folder = os.path.join(base_path, \"STEP_4_EDA\")\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "data_path = os.path.join(base_path, \"reduced_features_SMOTE_8028.csv\")\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"STEP 4 ‚Äî EXPLORATORY DATA ANALYSIS (EDA)\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# LOAD DATASET\n",
    "# ------------------------------------------------------------------\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "class_map = {\n",
    "    0: \"Underdried\",\n",
    "    1: \"Perfectly_Dried\",\n",
    "    2: \"Overdried\"\n",
    "}\n",
    "df['Class_Name'] = df['Class'].map(class_map)\n",
    "\n",
    "features = ['R', 'H_hsv', 'Contrast', 'Correlation', 'Energy']\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 1. SCATTER PLOTS (PAIRWISE)\n",
    "# ------------------------------------------------------------------\n",
    "scatter_folder = os.path.join(output_folder, \"Scatterplots\")\n",
    "os.makedirs(scatter_folder, exist_ok=True)\n",
    "\n",
    "print(\"\\nGenerating scatter plots...\")\n",
    "\n",
    "for x in features:\n",
    "    for y in features:\n",
    "        if x != y:\n",
    "            plt.figure()\n",
    "            for cls in class_map.values():\n",
    "                subset = df[df['Class_Name'] == cls]\n",
    "                plt.scatter(\n",
    "                    subset[x],\n",
    "                    subset[y],\n",
    "                    alpha=0.4,\n",
    "                    label=cls\n",
    "                )\n",
    "            plt.xlabel(x)\n",
    "            plt.ylabel(y)\n",
    "            plt.title(f\"{x} vs {y} by Class\")\n",
    "            plt.legend()\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(scatter_folder, f\"{x}_vs_{y}.png\"))\n",
    "            plt.close()\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 2. CORRELATION MATRIX (PER CLASS)\n",
    "# ------------------------------------------------------------------\n",
    "corr_folder = os.path.join(output_folder, \"Correlation_Matrix\")\n",
    "os.makedirs(corr_folder, exist_ok=True)\n",
    "\n",
    "print(\"\\nComputing correlation matrices...\")\n",
    "\n",
    "for cls, group in df.groupby('Class_Name'):\n",
    "    corr = group[features].corr()\n",
    "    corr.to_csv(os.path.join(corr_folder, f\"correlation_matrix_{cls}.csv\"))\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 3. HEATMAPS (CLEAN STYLE)\n",
    "# ------------------------------------------------------------------\n",
    "heatmap_folder = os.path.join(output_folder, \"Heatmaps\")\n",
    "os.makedirs(heatmap_folder, exist_ok=True)\n",
    "\n",
    "print(\"\\nGenerating clean correlation heatmaps...\")\n",
    "\n",
    "def plot_clean_heatmap(corr, title, filename):\n",
    "    plt.figure(figsize=(7, 6))\n",
    "    im = plt.imshow(corr, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "    plt.colorbar(im, fraction=0.046, pad=0.04)\n",
    "\n",
    "    plt.xticks(range(len(corr.columns)), corr.columns, rotation=45)\n",
    "    plt.yticks(range(len(corr.index)), corr.index)\n",
    "\n",
    "    # Annotate values\n",
    "    for i in range(len(corr.index)):\n",
    "        for j in range(len(corr.columns)):\n",
    "            plt.text(\n",
    "                j, i,\n",
    "                f\"{corr.iloc[i, j]:.2f}\",\n",
    "                ha=\"center\",\n",
    "                va=\"center\",\n",
    "                color=\"black\",\n",
    "                fontsize=10\n",
    "            )\n",
    "\n",
    "    plt.title(title, fontsize=13, pad=12)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(heatmap_folder, filename), dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# A. HEATMAP FOR ALL DATA (NO CLASS SEPARATION)\n",
    "# ------------------------------------------------------------------\n",
    "corr_all = df[features].corr()\n",
    "\n",
    "plot_clean_heatmap(\n",
    "    corr_all,\n",
    "    title=\"Reduced Feature Correlation Heatmap (All Data)\",\n",
    "    filename=\"heatmap_ALL_DATA.png\"\n",
    ")\n",
    "\n",
    "# Save numeric correlation matrix\n",
    "corr_all.to_csv(os.path.join(heatmap_folder, \"correlation_ALL_DATA.csv\"))\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# B. HEATMAPS PER CLASS\n",
    "# ------------------------------------------------------------------\n",
    "for cls, group in df.groupby('Class_Name'):\n",
    "    corr_class = group[features].corr()\n",
    "\n",
    "    plot_clean_heatmap(\n",
    "        corr_class,\n",
    "        title=f\"Reduced Feature Correlation Heatmap ({cls})\",\n",
    "        filename=f\"heatmap_{cls}.png\"\n",
    "    )\n",
    "\n",
    "    corr_class.to_csv(\n",
    "        os.path.join(heatmap_folder, f\"correlation_{cls}.csv\")\n",
    "    )\n",
    "\n",
    "print(\"Clean heatmaps generated successfully.\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nSTEP 4 EDA COMPLETED SUCCESSFULLY\")\n",
    "print(f\"üìÅ All outputs saved to: {output_folder}\")\n",
    "print(\"=\"*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "331fd967-131d-4e7d-83b4-6e4e4514e5e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "STEP 5 ‚Äî PROBABILITY DISTRIBUTION ANALYSIS\n",
      "====================================================================================================\n",
      "\n",
      "DISTRIBUTION SHAPE ANALYSIS\n",
      "------------------------------------------------------------\n",
      "Mean      : 77.0442\n",
      "Std Dev   : 129.9912\n",
      "Skewness  : 3.6266\n",
      "Kurtosis  : 16.0835\n",
      "Distribution Shape: Right-skewed (positively skewed)\n",
      "\n",
      "PROBABILITY CALCULATION\n",
      "------------------------------------------------------------\n",
      "P(Contrast < Mean + 1œÉ) = 0.8413\n",
      "\n",
      "PERCENTILES\n",
      "   Percentile  Contrast_Value\n",
      "0          10        5.313759\n",
      "1          25       12.448589\n",
      "2          50       29.823085\n",
      "3          75       81.356904\n",
      "4          90      191.472756\n",
      "\n",
      "ALL STEP 5 RESULTS SAVED SUCCESSFULLY\n",
      "üìÅ Location: C:\\Users\\Acer\\Downloads\\FINAL PROJECT\\STEP_5_PROBABILITY_ANALYSIS\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from scipy import stats\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# PATH SETUP\n",
    "# ------------------------------------------------------------------\n",
    "base_path = r\"C:\\Users\\Acer\\Downloads\\FINAL PROJECT\"\n",
    "output_folder = os.path.join(base_path, \"STEP_5_PROBABILITY_ANALYSIS\")\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "data_path = os.path.join(base_path, \"reduced_features_SMOTE_8028.csv\")\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"STEP 5 ‚Äî PROBABILITY DISTRIBUTION ANALYSIS\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# LOAD DATASET\n",
    "# ------------------------------------------------------------------\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "variable = \"Contrast\"\n",
    "data = df[variable]\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 1. DISTRIBUTION SHAPE\n",
    "# ------------------------------------------------------------------\n",
    "mean_val = data.mean()\n",
    "std_val = data.std()\n",
    "skewness = stats.skew(data)\n",
    "kurtosis = stats.kurtosis(data)\n",
    "\n",
    "print(\"\\nDISTRIBUTION SHAPE ANALYSIS\")\n",
    "print(\"-\"*60)\n",
    "print(f\"Mean      : {mean_val:.4f}\")\n",
    "print(f\"Std Dev   : {std_val:.4f}\")\n",
    "print(f\"Skewness  : {skewness:.4f}\")\n",
    "print(f\"Kurtosis  : {kurtosis:.4f}\")\n",
    "\n",
    "# Interpretation logic\n",
    "if skewness > 0:\n",
    "    shape = \"Right-skewed (positively skewed)\"\n",
    "elif skewness < 0:\n",
    "    shape = \"Left-skewed (negatively skewed)\"\n",
    "else:\n",
    "    shape = \"Approximately symmetric\"\n",
    "\n",
    "print(f\"Distribution Shape: {shape}\")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 2. Z-SCORES & PROBABILITY CALCULATIONS\n",
    "# ------------------------------------------------------------------\n",
    "z_scores = (data - mean_val) / std_val\n",
    "\n",
    "df_z = pd.DataFrame({\n",
    "    variable: data,\n",
    "    \"Z_Score\": z_scores\n",
    "})\n",
    "\n",
    "df_z.to_csv(os.path.join(output_folder, \"contrast_z_scores.csv\"), index=False)\n",
    "\n",
    "# Example probability: P(X < Mean + 1 Std)\n",
    "threshold = mean_val + std_val\n",
    "probability = stats.norm.cdf(threshold, mean_val, std_val)\n",
    "\n",
    "print(\"\\nPROBABILITY CALCULATION\")\n",
    "print(\"-\"*60)\n",
    "print(f\"P({variable} < Mean + 1œÉ) = {probability:.4f}\")\n",
    "\n",
    "# Percentiles\n",
    "percentiles = [10, 25, 50, 75, 90]\n",
    "percentile_values = np.percentile(data, percentiles)\n",
    "\n",
    "percentile_table = pd.DataFrame({\n",
    "    \"Percentile\": percentiles,\n",
    "    \"Contrast_Value\": percentile_values\n",
    "})\n",
    "\n",
    "percentile_table.to_csv(\n",
    "    os.path.join(output_folder, \"contrast_percentiles.csv\"),\n",
    "    index=False\n",
    ")\n",
    "\n",
    "print(\"\\nPERCENTILES\")\n",
    "print(percentile_table)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 3. PROBABILITY PLOTS\n",
    "# ------------------------------------------------------------------\n",
    "# Histogram with Normal Curve\n",
    "plt.figure()\n",
    "plt.hist(data, bins=40, density=True, alpha=0.6)\n",
    "xmin, xmax = plt.xlim()\n",
    "x = np.linspace(xmin, xmax, 200)\n",
    "p = stats.norm.pdf(x, mean_val, std_val)\n",
    "plt.plot(x, p)\n",
    "plt.title(\"Contrast Distribution with Normal Curve\")\n",
    "plt.xlabel(\"Contrast\")\n",
    "plt.ylabel(\"Probability Density\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_folder, \"contrast_histogram_normal.png\"))\n",
    "plt.close()\n",
    "\n",
    "# Q-Q Plot\n",
    "plt.figure()\n",
    "stats.probplot(data, dist=\"norm\", plot=plt)\n",
    "plt.title(\"Q-Q Plot for Contrast\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_folder, \"contrast_qq_plot.png\"))\n",
    "plt.close()\n",
    "\n",
    "print(\"\\nALL STEP 5 RESULTS SAVED SUCCESSFULLY\")\n",
    "print(f\"üìÅ Location: {output_folder}\")\n",
    "print(\"=\"*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "715f37ae-fcf5-4e5c-abf9-e5697085cf39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "STEP 6 ‚Äî REGRESSION ANALYSIS\n",
      "====================================================================================================\n",
      "\n",
      "SIMPLE LINEAR REGRESSION\n",
      "----------------------------------------------------------------------------------------------------\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:               Contrast   R-squared:                       0.197\n",
      "Model:                            OLS   Adj. R-squared:                  0.197\n",
      "Method:                 Least Squares   F-statistic:                     5898.\n",
      "Date:                Sun, 21 Dec 2025   Prob (F-statistic):               0.00\n",
      "Time:                        22:44:07   Log-Likelihood:            -1.4876e+05\n",
      "No. Observations:               24084   AIC:                         2.975e+05\n",
      "Df Residuals:                   24082   BIC:                         2.975e+05\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        185.5739      1.600    115.965      0.000     182.437     188.711\n",
      "Energy     -1561.9700     20.339    -76.796      0.000   -1601.836   -1522.104\n",
      "==============================================================================\n",
      "Omnibus:                    18250.849   Durbin-Watson:                   1.261\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           336385.532\n",
      "Skew:                           3.589   Prob(JB):                         0.00\n",
      "Kurtosis:                      19.843   Cond. No.                         27.2\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "Regression Equation:\n",
      "Contrast = 185.5739 + -1561.9700(Energy)\n",
      "\n",
      "MULTIPLE LINEAR REGRESSION\n",
      "----------------------------------------------------------------------------------------------------\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:               Contrast   R-squared:                       0.244\n",
      "Model:                            OLS   Adj. R-squared:                  0.244\n",
      "Method:                 Least Squares   F-statistic:                     1946.\n",
      "Date:                Sun, 21 Dec 2025   Prob (F-statistic):               0.00\n",
      "Time:                        22:44:07   Log-Likelihood:            -1.4803e+05\n",
      "No. Observations:               24084   AIC:                         2.961e+05\n",
      "Df Residuals:                   24079   BIC:                         2.961e+05\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===============================================================================\n",
      "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------\n",
      "const         288.8595      5.823     49.606      0.000     277.446     300.273\n",
      "R               0.1986      0.017     11.381      0.000       0.164       0.233\n",
      "H_hsv           0.4663      0.028     16.703      0.000       0.412       0.521\n",
      "Correlation  -183.0223      6.768    -27.041      0.000    -196.288    -169.756\n",
      "Energy      -1447.2910     21.197    -68.279      0.000   -1488.838   -1405.744\n",
      "==============================================================================\n",
      "Omnibus:                    18171.671   Durbin-Watson:                   1.232\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           342481.483\n",
      "Skew:                           3.555   Prob(JB):                         0.00\n",
      "Kurtosis:                      20.051   Cond. No.                     4.48e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 4.48e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "\n",
      "ALL STEP 6 RESULTS SAVED SUCCESSFULLY\n",
      "üìÅ Location: C:\\Users\\Acer\\Downloads\\FINAL PROJECT\\STEP_6_REGRESSION_ANALYSIS\n",
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# PATH SETUP\n",
    "# ------------------------------------------------------------------\n",
    "base_path = r\"C:\\Users\\Acer\\Downloads\\FINAL PROJECT\"\n",
    "output_folder = os.path.join(base_path, \"STEP_6_REGRESSION_ANALYSIS\")\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "data_path = os.path.join(base_path, \"reduced_features_SMOTE_8028.csv\")\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"STEP 6 ‚Äî REGRESSION ANALYSIS\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# LOAD DATASET\n",
    "# ------------------------------------------------------------------\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# ================================================================\n",
    "# 1. SIMPLE LINEAR REGRESSION\n",
    "# ================================================================\n",
    "print(\"\\nSIMPLE LINEAR REGRESSION\")\n",
    "print(\"-\"*100)\n",
    "\n",
    "X_simple = df['Energy']\n",
    "y = df['Contrast']\n",
    "\n",
    "X_simple = sm.add_constant(X_simple)\n",
    "simple_model = sm.OLS(y, X_simple).fit()\n",
    "\n",
    "print(simple_model.summary())\n",
    "\n",
    "# Save summary\n",
    "with open(os.path.join(output_folder, \"simple_regression_summary.txt\"), \"w\") as f:\n",
    "    f.write(simple_model.summary().as_text())\n",
    "\n",
    "# Regression equation\n",
    "b0, b1 = simple_model.params\n",
    "print(f\"\\nRegression Equation:\")\n",
    "print(f\"Contrast = {b0:.4f} + {b1:.4f}(Energy)\")\n",
    "\n",
    "# Residual plot\n",
    "plt.figure()\n",
    "plt.scatter(simple_model.fittedvalues, simple_model.resid, alpha=0.5)\n",
    "plt.axhline(0)\n",
    "plt.xlabel(\"Fitted Values\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.title(\"Residual Plot ‚Äî Simple Linear Regression\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_folder, \"simple_regression_residuals.png\"))\n",
    "plt.close()\n",
    "\n",
    "# ================================================================\n",
    "# 2. MULTIPLE LINEAR REGRESSION\n",
    "# ================================================================\n",
    "print(\"\\nMULTIPLE LINEAR REGRESSION\")\n",
    "print(\"-\"*100)\n",
    "\n",
    "X_multi = df[['R', 'H_hsv', 'Correlation', 'Energy']]\n",
    "X_multi = sm.add_constant(X_multi)\n",
    "\n",
    "multi_model = sm.OLS(y, X_multi).fit()\n",
    "print(multi_model.summary())\n",
    "\n",
    "# Save summary\n",
    "with open(os.path.join(output_folder, \"multiple_regression_summary.txt\"), \"w\") as f:\n",
    "    f.write(multi_model.summary().as_text())\n",
    "\n",
    "# ================================================================\n",
    "# RESIDUAL DIAGNOSTICS\n",
    "# ================================================================\n",
    "# Residual vs Fitted\n",
    "plt.figure()\n",
    "plt.scatter(multi_model.fittedvalues, multi_model.resid, alpha=0.5)\n",
    "plt.axhline(0)\n",
    "plt.xlabel(\"Fitted Values\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.title(\"Residual Plot ‚Äî Multiple Linear Regression\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_folder, \"multiple_regression_residuals.png\"))\n",
    "plt.close()\n",
    "\n",
    "# Q-Q Plot\n",
    "plt.figure()\n",
    "sm.qqplot(multi_model.resid, line='45', fit=True)\n",
    "plt.title(\"Q-Q Plot ‚Äî Multiple Linear Regression Residuals\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_folder, \"multiple_regression_qq.png\"))\n",
    "plt.close()\n",
    "\n",
    "print(\"\\nALL STEP 6 RESULTS SAVED SUCCESSFULLY\")\n",
    "print(f\"üìÅ Location: {output_folder}\")\n",
    "print(\"=\"*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6c997daf-be09-4ee6-b0fe-b70f76bb47cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "STEP 8 ‚Äî ONE-WAY ANOVA\n",
      "====================================================================================================\n",
      "\n",
      "ANOVA ‚Äî R\n",
      "F-statistic = 29983.3792\n",
      "p-value     = 0.000000\n",
      "‚Üí Significant result: running Tukey HSD post-hoc test\n",
      "           Multiple Comparison of Means - Tukey HSD, FWER=0.05            \n",
      "==========================================================================\n",
      "     group1          group2      meandiff p-adj   lower     upper   reject\n",
      "--------------------------------------------------------------------------\n",
      "      Overdried Perfectly_Dried  -93.4961   0.0  -94.5884  -92.4038   True\n",
      "      Overdried      Underdried -103.4146   0.0 -104.5068 -102.3223   True\n",
      "Perfectly_Dried      Underdried   -9.9185   0.0  -11.0107   -8.8262   True\n",
      "--------------------------------------------------------------------------\n",
      "\n",
      "ANOVA ‚Äî H_hsv\n",
      "F-statistic = 7137.3116\n",
      "p-value     = 0.000000\n",
      "‚Üí Significant result: running Tukey HSD post-hoc test\n",
      "          Multiple Comparison of Means - Tukey HSD, FWER=0.05          \n",
      "=======================================================================\n",
      "     group1          group2     meandiff p-adj  lower    upper   reject\n",
      "-----------------------------------------------------------------------\n",
      "      Overdried Perfectly_Dried -49.7869   0.0 -50.8149  -48.759   True\n",
      "      Overdried      Underdried -39.0471   0.0  -40.075 -38.0191   True\n",
      "Perfectly_Dried      Underdried  10.7399   0.0   9.7119  11.7679   True\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "ANOVA ‚Äî Contrast\n",
      "F-statistic = 1045.6462\n",
      "p-value     = 0.000000\n",
      "‚Üí Significant result: running Tukey HSD post-hoc test\n",
      "          Multiple Comparison of Means - Tukey HSD, FWER=0.05          \n",
      "=======================================================================\n",
      "     group1          group2     meandiff p-adj  lower    upper   reject\n",
      "-----------------------------------------------------------------------\n",
      "      Overdried Perfectly_Dried -16.0332   0.0 -20.6463 -11.4202   True\n",
      "      Overdried      Underdried  68.6834   0.0  64.0703  73.2965   True\n",
      "Perfectly_Dried      Underdried  84.7166   0.0  80.1036  89.3297   True\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "ANOVA ‚Äî Correlation\n",
      "F-statistic = 665.7887\n",
      "p-value     = 0.000000\n",
      "‚Üí Significant result: running Tukey HSD post-hoc test\n",
      "         Multiple Comparison of Means - Tukey HSD, FWER=0.05         \n",
      "=====================================================================\n",
      "     group1          group2     meandiff p-adj  lower   upper  reject\n",
      "---------------------------------------------------------------------\n",
      "      Overdried Perfectly_Dried  -0.0593   0.0 -0.0633 -0.0554   True\n",
      "      Overdried      Underdried  -0.0448   0.0 -0.0488 -0.0408   True\n",
      "Perfectly_Dried      Underdried   0.0145   0.0  0.0106  0.0185   True\n",
      "---------------------------------------------------------------------\n",
      "\n",
      "ANOVA ‚Äî Energy\n",
      "F-statistic = 692.7998\n",
      "p-value     = 0.000000\n",
      "‚Üí Significant result: running Tukey HSD post-hoc test\n",
      "         Multiple Comparison of Means - Tukey HSD, FWER=0.05         \n",
      "=====================================================================\n",
      "     group1          group2     meandiff p-adj  lower   upper  reject\n",
      "---------------------------------------------------------------------\n",
      "      Overdried Perfectly_Dried  -0.0076   0.0 -0.0089 -0.0062   True\n",
      "      Overdried      Underdried  -0.0208   0.0 -0.0222 -0.0195   True\n",
      "Perfectly_Dried      Underdried  -0.0133   0.0 -0.0146 -0.0119   True\n",
      "---------------------------------------------------------------------\n",
      "\n",
      "ALL STEP 8 RESULTS SAVED SUCCESSFULLY\n",
      "üìÅ Location: C:\\Users\\Acer\\Downloads\\FINAL PROJECT\\STEP_8_ANOVA\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from scipy.stats import f_oneway\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# PATH SETUP\n",
    "# ------------------------------------------------------------------\n",
    "base_path = r\"C:\\Users\\Acer\\Downloads\\FINAL PROJECT\"\n",
    "output_folder = os.path.join(base_path, \"STEP_8_ANOVA\")\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "data_path = os.path.join(base_path, \"reduced_features_SMOTE_8028.csv\")\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"STEP 8 ‚Äî ONE-WAY ANOVA\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# LOAD DATASET\n",
    "# ------------------------------------------------------------------\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "class_map = {\n",
    "    0: \"Underdried\",\n",
    "    1: \"Perfectly_Dried\",\n",
    "    2: \"Overdried\"\n",
    "}\n",
    "df['Class_Name'] = df['Class'].map(class_map)\n",
    "\n",
    "features = ['R', 'H_hsv', 'Contrast', 'Correlation', 'Energy']\n",
    "\n",
    "anova_results = []\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# ONE-WAY ANOVA PER FEATURE\n",
    "# ------------------------------------------------------------------\n",
    "for feature in features:\n",
    "    group0 = df[df['Class'] == 0][feature]\n",
    "    group1 = df[df['Class'] == 1][feature]\n",
    "    group2 = df[df['Class'] == 2][feature]\n",
    "\n",
    "    F_stat, p_value = f_oneway(group0, group1, group2)\n",
    "\n",
    "    anova_results.append({\n",
    "        \"Feature\": feature,\n",
    "        \"F_statistic\": F_stat,\n",
    "        \"p_value\": p_value\n",
    "    })\n",
    "\n",
    "    print(f\"\\nANOVA ‚Äî {feature}\")\n",
    "    print(f\"F-statistic = {F_stat:.4f}\")\n",
    "    print(f\"p-value     = {p_value:.6f}\")\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # POST-HOC TEST (Tukey HSD) IF SIGNIFICANT\n",
    "    # ------------------------------------------------------------------\n",
    "    if p_value < 0.05:\n",
    "        print(\"‚Üí Significant result: running Tukey HSD post-hoc test\")\n",
    "\n",
    "        tukey = pairwise_tukeyhsd(\n",
    "            endog=df[feature],\n",
    "            groups=df['Class_Name'],\n",
    "            alpha=0.05\n",
    "        )\n",
    "\n",
    "        # Save Tukey results\n",
    "        tukey_df = pd.DataFrame(\n",
    "            data=tukey.summary().data[1:],\n",
    "            columns=tukey.summary().data[0]\n",
    "        )\n",
    "\n",
    "        tukey_df.to_csv(\n",
    "            os.path.join(output_folder, f\"tukey_{feature}.csv\"),\n",
    "            index=False\n",
    "        )\n",
    "\n",
    "        print(tukey.summary())\n",
    "    else:\n",
    "        print(\"‚Üí Not significant: post-hoc test not required\")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# SAVE ANOVA SUMMARY\n",
    "# ------------------------------------------------------------------\n",
    "anova_df = pd.DataFrame(anova_results)\n",
    "anova_df.to_csv(os.path.join(output_folder, \"anova_summary.csv\"), index=False)\n",
    "\n",
    "print(\"\\nALL STEP 8 RESULTS SAVED SUCCESSFULLY\")\n",
    "print(f\"üìÅ Location: {output_folder}\")\n",
    "print(\"=\"*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c7ce37aa-996a-49ce-8318-a0c2ac0db8de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA completed successfully.\n",
      "Explained variance ratios:\n",
      "PC1: 36.42%\n",
      "PC2: 29.13%\n",
      "PC3: 17.12%\n",
      "Plots saved in: C:\\Users\\Acer\\Downloads\\FINAL PROJECT\\STEP_4_EDA\\PCA_Plots\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import os\n",
    "\n",
    "# --------------------------------------------------\n",
    "# PATH SETUP\n",
    "# --------------------------------------------------\n",
    "base_path = r\"C:\\Users\\Acer\\Downloads\\FINAL PROJECT\"\n",
    "data_path = os.path.join(base_path, \"reduced_features_SMOTE_8028.csv\")\n",
    "output_folder = os.path.join(base_path, \"STEP_4_EDA\", \"PCA_Plots\")\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# LOAD DATA\n",
    "# --------------------------------------------------\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "features = [\"R\", \"H_hsv\", \"Contrast\", \"Correlation\", \"Energy\"]\n",
    "X = df[features]\n",
    "y = df[\"Class\"]\n",
    "\n",
    "# --------------------------------------------------\n",
    "# STANDARDIZE FEATURES\n",
    "# --------------------------------------------------\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# PCA (3 COMPONENTS)\n",
    "# --------------------------------------------------\n",
    "pca = PCA(n_components=3)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "explained_var = pca.explained_variance_ratio_ * 100\n",
    "\n",
    "# --------------------------------------------------\n",
    "# PCA 2D SCATTER PLOT\n",
    "# --------------------------------------------------\n",
    "plt.figure(figsize=(7, 6))\n",
    "scatter = plt.scatter(\n",
    "    X_pca[:, 0],\n",
    "    X_pca[:, 1],\n",
    "    c=y,\n",
    "    cmap=\"viridis\",\n",
    "    alpha=0.6,\n",
    "    s=15\n",
    ")\n",
    "\n",
    "plt.xlabel(f\"PC1 ({explained_var[0]:.1f}%)\")\n",
    "plt.ylabel(f\"PC2 ({explained_var[1]:.1f}%)\")\n",
    "plt.title(\"PCA: 2D Projection\")\n",
    "plt.colorbar(scatter, label=\"Class\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_folder, \"PCA_2D.png\"), dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# --------------------------------------------------\n",
    "# PCA 3D SCATTER PLOT\n",
    "# --------------------------------------------------\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = fig.add_subplot(111, projection=\"3d\")\n",
    "\n",
    "p = ax.scatter(\n",
    "    X_pca[:, 0],\n",
    "    X_pca[:, 1],\n",
    "    X_pca[:, 2],\n",
    "    c=y,\n",
    "    cmap=\"viridis\",\n",
    "    alpha=0.6,\n",
    "    s=15\n",
    ")\n",
    "\n",
    "ax.set_xlabel(f\"PC1 ({explained_var[0]:.1f}%)\")\n",
    "ax.set_ylabel(f\"PC2 ({explained_var[1]:.1f}%)\")\n",
    "ax.set_zlabel(f\"PC3 ({explained_var[2]:.1f}%)\")\n",
    "ax.set_title(\"PCA: 3D Projection\")\n",
    "\n",
    "fig.colorbar(p, label=\"Class\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_folder, \"PCA_3D.png\"), dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# --------------------------------------------------\n",
    "# PRINT SUMMARY\n",
    "# --------------------------------------------------\n",
    "print(\"PCA completed successfully.\")\n",
    "print(f\"Explained variance ratios:\")\n",
    "print(f\"PC1: {explained_var[0]:.2f}%\")\n",
    "print(f\"PC2: {explained_var[1]:.2f}%\")\n",
    "print(f\"PC3: {explained_var[2]:.2f}%\")\n",
    "print(f\"Plots saved in: {output_folder}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "56da9a79-4c3c-457b-9706-9e70785c07bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully\n",
      "Shape: (24084, 6)\n",
      "Columns: ['R', 'H_hsv', 'Contrast', 'Correlation', 'Energy', 'Class']\n",
      "\n",
      "============================================================\n",
      "SIMPLE LINEAR REGRESSION\n",
      "Y = Contrast | X = Energy\n",
      "============================================================\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:               Contrast   R-squared:                       0.197\n",
      "Model:                            OLS   Adj. R-squared:                  0.197\n",
      "Method:                 Least Squares   F-statistic:                     5898.\n",
      "Date:                Wed, 24 Dec 2025   Prob (F-statistic):               0.00\n",
      "Time:                        15:16:28   Log-Likelihood:            -1.4876e+05\n",
      "No. Observations:               24084   AIC:                         2.975e+05\n",
      "Df Residuals:                   24082   BIC:                         2.975e+05\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        185.5739      1.600    115.965      0.000     182.437     188.711\n",
      "Energy     -1561.9700     20.339    -76.796      0.000   -1601.836   -1522.104\n",
      "==============================================================================\n",
      "Omnibus:                    18250.849   Durbin-Watson:                   1.261\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           336385.532\n",
      "Skew:                           3.589   Prob(JB):                         0.00\n",
      "Kurtosis:                      19.843   Cond. No.                         27.2\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "Regression Equation:\n",
      "Contrast = 185.5739 + -1561.9700(Energy)\n",
      "R¬≤ = 0.1967\n",
      "\n",
      "============================================================\n",
      "MULTIPLE LINEAR REGRESSION\n",
      "Y = Contrast\n",
      "X = R, H_hsv, Correlation, Energy\n",
      "============================================================\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:               Contrast   R-squared:                       0.244\n",
      "Model:                            OLS   Adj. R-squared:                  0.244\n",
      "Method:                 Least Squares   F-statistic:                     1946.\n",
      "Date:                Wed, 24 Dec 2025   Prob (F-statistic):               0.00\n",
      "Time:                        15:16:30   Log-Likelihood:            -1.4803e+05\n",
      "No. Observations:               24084   AIC:                         2.961e+05\n",
      "Df Residuals:                   24079   BIC:                         2.961e+05\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===============================================================================\n",
      "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------\n",
      "const         288.8595      5.823     49.606      0.000     277.446     300.273\n",
      "R               0.1986      0.017     11.381      0.000       0.164       0.233\n",
      "H_hsv           0.4663      0.028     16.703      0.000       0.412       0.521\n",
      "Correlation  -183.0223      6.768    -27.041      0.000    -196.288    -169.756\n",
      "Energy      -1447.2910     21.197    -68.279      0.000   -1488.838   -1405.744\n",
      "==============================================================================\n",
      "Omnibus:                    18171.671   Durbin-Watson:                   1.232\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           342481.483\n",
      "Skew:                           3.555   Prob(JB):                         0.00\n",
      "Kurtosis:                      20.051   Cond. No.                     4.48e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 4.48e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "\n",
      "Regression Equation:\n",
      "Contrast = 288.8595 + 0.1986(R) + 0.4663(H_hsv) + -183.0223(Correlation) + -1447.2910(Energy)\n",
      "R¬≤ = 0.2443\n",
      "Adjusted R¬≤ = 0.2442\n",
      "\n",
      "STEP 6 completed successfully.\n",
      "All outputs saved in:\n",
      "C:\\Users\\Acer\\Downloads\\FINAL PROJECT\\STEP_6_Regression_Results\n"
     ]
    }
   ],
   "source": [
    "# STEP 6 ‚Äî REGRESSION ANALYSIS\n",
    "# Simple Linear Regression & Multiple Linear Regression\n",
    "# Uses SMOTED dataset: reduced_features_SMOTE_8028.csv\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "\n",
    "# ============================\n",
    "# FILE PATHS (FIXED)\n",
    "# ============================\n",
    "DATA_PATH = r\"C:\\Users\\Acer\\Downloads\\FINAL PROJECT\\reduced_features_SMOTE_8028.csv\"\n",
    "OUTPUT_DIR = r\"C:\\Users\\Acer\\Downloads\\FINAL PROJECT\\STEP_6_Regression_Results\"\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# ============================\n",
    "# LOAD DATA\n",
    "# ============================\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "print(\"Dataset loaded successfully\")\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"Columns:\", df.columns.tolist())\n",
    "\n",
    "# ============================\n",
    "# 1. SIMPLE LINEAR REGRESSION\n",
    "# Y = Contrast | X = Energy\n",
    "# ============================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SIMPLE LINEAR REGRESSION\")\n",
    "print(\"Y = Contrast | X = Energy\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "X_simple = df[\"Energy\"]\n",
    "Y_simple = df[\"Contrast\"]\n",
    "\n",
    "X_simple_const = sm.add_constant(X_simple)\n",
    "simple_model = sm.OLS(Y_simple, X_simple_const).fit()\n",
    "\n",
    "# Print regression summary\n",
    "print(simple_model.summary())\n",
    "\n",
    "# Regression equation\n",
    "b0, b1 = simple_model.params\n",
    "print(f\"\\nRegression Equation:\")\n",
    "print(f\"Contrast = {b0:.4f} + {b1:.4f}(Energy)\")\n",
    "print(f\"R¬≤ = {simple_model.rsquared:.4f}\")\n",
    "\n",
    "# ============================\n",
    "# SIMPLE REGRESSION DIAGNOSTICS\n",
    "# ============================\n",
    "residuals_simple = simple_model.resid\n",
    "fitted_simple = simple_model.fittedvalues\n",
    "\n",
    "# Residual vs Fitted\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.scatterplot(x=fitted_simple, y=residuals_simple, alpha=0.5)\n",
    "plt.axhline(0, color='red')\n",
    "plt.xlabel(\"Fitted Values\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.title(\"Residual Plot ‚Äî Simple Linear Regression\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, \"simple_regression_residuals.png\"))\n",
    "plt.close()\n",
    "\n",
    "# Q-Q Plot\n",
    "plt.figure(figsize=(6,4))\n",
    "stats.probplot(residuals_simple, plot=plt)\n",
    "plt.title(\"Q-Q Plot ‚Äî Simple Linear Regression Residuals\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, \"simple_regression_qq.png\"))\n",
    "plt.close()\n",
    "\n",
    "# ============================\n",
    "# 2. MULTIPLE LINEAR REGRESSION\n",
    "# Y = Contrast\n",
    "# X = R, H_hsv, Correlation, Energy\n",
    "# ============================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MULTIPLE LINEAR REGRESSION\")\n",
    "print(\"Y = Contrast\")\n",
    "print(\"X = R, H_hsv, Correlation, Energy\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "X_multi = df[[\"R\", \"H_hsv\", \"Correlation\", \"Energy\"]]\n",
    "Y_multi = df[\"Contrast\"]\n",
    "\n",
    "X_multi_const = sm.add_constant(X_multi)\n",
    "multi_model = sm.OLS(Y_multi, X_multi_const).fit()\n",
    "\n",
    "# Print regression summary\n",
    "print(multi_model.summary())\n",
    "\n",
    "# Regression equation\n",
    "params = multi_model.params\n",
    "print(\"\\nRegression Equation:\")\n",
    "print(\n",
    "    f\"Contrast = {params['const']:.4f} \"\n",
    "    f\"+ {params['R']:.4f}(R) \"\n",
    "    f\"+ {params['H_hsv']:.4f}(H_hsv) \"\n",
    "    f\"+ {params['Correlation']:.4f}(Correlation) \"\n",
    "    f\"+ {params['Energy']:.4f}(Energy)\"\n",
    ")\n",
    "\n",
    "print(f\"R¬≤ = {multi_model.rsquared:.4f}\")\n",
    "print(f\"Adjusted R¬≤ = {multi_model.rsquared_adj:.4f}\")\n",
    "\n",
    "# ============================\n",
    "# MULTIPLE REGRESSION DIAGNOSTICS\n",
    "# ============================\n",
    "residuals_multi = multi_model.resid\n",
    "fitted_multi = multi_model.fittedvalues\n",
    "\n",
    "# Residual vs Fitted\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.scatterplot(x=fitted_multi, y=residuals_multi, alpha=0.5)\n",
    "plt.axhline(0, color='red')\n",
    "plt.xlabel(\"Fitted Values\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.title(\"Residual Plot ‚Äî Multiple Linear Regression\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, \"multiple_regression_residuals.png\"))\n",
    "plt.close()\n",
    "\n",
    "# Q-Q Plot\n",
    "plt.figure(figsize=(6,4))\n",
    "stats.probplot(residuals_multi, plot=plt)\n",
    "plt.title(\"Q-Q Plot ‚Äî Multiple Linear Regression Residuals\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, \"multiple_regression_qq.png\"))\n",
    "plt.close()\n",
    "\n",
    "print(\"\\nSTEP 6 completed successfully.\")\n",
    "print(f\"All outputs saved in:\\n{OUTPUT_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6ef455a3-4e53-4576-b0c7-9c8fd789d1ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully\n",
      "Shape: (24084, 7)\n",
      "\n",
      "============================================================\n",
      "STEP 8 ‚Äî ONE-WAY ANOVA RESULTS\n",
      "============================================================\n",
      "\n",
      "Feature: R\n",
      "F-statistic = 29983.3792\n",
      "p-value     = 0.000000e+00\n",
      "\n",
      "Feature: H_hsv\n",
      "F-statistic = 7137.3116\n",
      "p-value     = 0.000000e+00\n",
      "\n",
      "Feature: Contrast\n",
      "F-statistic = 1045.6462\n",
      "p-value     = 0.000000e+00\n",
      "\n",
      "Feature: Correlation\n",
      "F-statistic = 665.7887\n",
      "p-value     = 3.655790e-282\n",
      "\n",
      "Feature: Energy\n",
      "F-statistic = 692.7998\n",
      "p-value     = 2.875354e-293\n",
      "\n",
      "============================================================\n",
      "TUKEY HSD POST-HOC TEST\n",
      "============================================================\n",
      "\n",
      "Tukey results for R\n",
      "           Multiple Comparison of Means - Tukey HSD, FWER=0.05            \n",
      "==========================================================================\n",
      "     group1          group2      meandiff p-adj   lower     upper   reject\n",
      "--------------------------------------------------------------------------\n",
      "      Overdried Perfectly Dried  -93.4961   0.0  -94.5884  -92.4038   True\n",
      "      Overdried      Underdried -103.4146   0.0 -104.5068 -102.3223   True\n",
      "Perfectly Dried      Underdried   -9.9185   0.0  -11.0107   -8.8262   True\n",
      "--------------------------------------------------------------------------\n",
      "\n",
      "Tukey results for H_hsv\n",
      "          Multiple Comparison of Means - Tukey HSD, FWER=0.05          \n",
      "=======================================================================\n",
      "     group1          group2     meandiff p-adj  lower    upper   reject\n",
      "-----------------------------------------------------------------------\n",
      "      Overdried Perfectly Dried -49.7869   0.0 -50.8149  -48.759   True\n",
      "      Overdried      Underdried -39.0471   0.0  -40.075 -38.0191   True\n",
      "Perfectly Dried      Underdried  10.7399   0.0   9.7119  11.7679   True\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "Tukey results for Contrast\n",
      "          Multiple Comparison of Means - Tukey HSD, FWER=0.05          \n",
      "=======================================================================\n",
      "     group1          group2     meandiff p-adj  lower    upper   reject\n",
      "-----------------------------------------------------------------------\n",
      "      Overdried Perfectly Dried -16.0332   0.0 -20.6463 -11.4202   True\n",
      "      Overdried      Underdried  68.6834   0.0  64.0703  73.2965   True\n",
      "Perfectly Dried      Underdried  84.7166   0.0  80.1036  89.3297   True\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "Tukey results for Correlation\n",
      "         Multiple Comparison of Means - Tukey HSD, FWER=0.05         \n",
      "=====================================================================\n",
      "     group1          group2     meandiff p-adj  lower   upper  reject\n",
      "---------------------------------------------------------------------\n",
      "      Overdried Perfectly Dried  -0.0593   0.0 -0.0633 -0.0554   True\n",
      "      Overdried      Underdried  -0.0448   0.0 -0.0488 -0.0408   True\n",
      "Perfectly Dried      Underdried   0.0145   0.0  0.0106  0.0185   True\n",
      "---------------------------------------------------------------------\n",
      "\n",
      "Tukey results for Energy\n",
      "         Multiple Comparison of Means - Tukey HSD, FWER=0.05         \n",
      "=====================================================================\n",
      "     group1          group2     meandiff p-adj  lower   upper  reject\n",
      "---------------------------------------------------------------------\n",
      "      Overdried Perfectly Dried  -0.0076   0.0 -0.0089 -0.0062   True\n",
      "      Overdried      Underdried  -0.0208   0.0 -0.0222 -0.0195   True\n",
      "Perfectly Dried      Underdried  -0.0133   0.0 -0.0146 -0.0119   True\n",
      "---------------------------------------------------------------------\n",
      "\n",
      "Generating ANOVA visualization images...\n",
      "\n",
      "STEP 8 completed successfully.\n",
      "All results and images saved in:\n",
      "C:\\Users\\Acer\\Downloads\\FINAL PROJECT\\STEP_8_ANOVA_RESULTS\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# STEP 8 ‚Äî ONE-WAY ANOVA + TUKEY + VISUALIZATION\n",
    "# ============================================\n",
    "\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# ============================\n",
    "# CONFIGURATION\n",
    "# ============================\n",
    "DATA_PATH = r\"C:\\Users\\Acer\\Downloads\\FINAL PROJECT\\reduced_features_SMOTE_8028.csv\"\n",
    "OUTPUT_DIR = r\"C:\\Users\\Acer\\Downloads\\FINAL PROJECT\\STEP_8_ANOVA_RESULTS\"\n",
    "\n",
    "FEATURES = [\"R\", \"H_hsv\", \"Contrast\", \"Correlation\", \"Energy\"]\n",
    "CLASS_COL = \"Class\"\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# ============================\n",
    "# LOAD DATA\n",
    "# ============================\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "class_map = {\n",
    "    0: \"Underdried\",\n",
    "    1: \"Perfectly Dried\",\n",
    "    2: \"Overdried\"\n",
    "}\n",
    "df[\"Class_Name\"] = df[CLASS_COL].map(class_map)\n",
    "\n",
    "print(\"Dataset loaded successfully\")\n",
    "print(\"Shape:\", df.shape)\n",
    "\n",
    "# ============================\n",
    "# ONE-WAY ANOVA\n",
    "# ============================\n",
    "anova_results = []\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 8 ‚Äî ONE-WAY ANOVA RESULTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for feature in FEATURES:\n",
    "    groups = [\n",
    "        df[df[CLASS_COL] == cls][feature]\n",
    "        for cls in sorted(df[CLASS_COL].unique())\n",
    "    ]\n",
    "\n",
    "    F_stat, p_value = stats.f_oneway(*groups)\n",
    "\n",
    "    anova_results.append({\n",
    "        \"Feature\": feature,\n",
    "        \"F_statistic\": F_stat,\n",
    "        \"p_value\": p_value\n",
    "    })\n",
    "\n",
    "    print(f\"\\nFeature: {feature}\")\n",
    "    print(f\"F-statistic = {F_stat:.4f}\")\n",
    "    print(f\"p-value     = {p_value:.6e}\")\n",
    "\n",
    "# Save ANOVA numeric results\n",
    "anova_df = pd.DataFrame(anova_results)\n",
    "anova_df.to_csv(os.path.join(OUTPUT_DIR, \"anova_summary.csv\"), index=False)\n",
    "\n",
    "# ============================\n",
    "# TUKEY POST-HOC TEST\n",
    "# ============================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TUKEY HSD POST-HOC TEST\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for feature in FEATURES:\n",
    "    tukey = pairwise_tukeyhsd(\n",
    "        endog=df[feature],\n",
    "        groups=df[\"Class_Name\"],\n",
    "        alpha=0.05\n",
    "    )\n",
    "\n",
    "    print(f\"\\nTukey results for {feature}\")\n",
    "    print(tukey.summary())\n",
    "\n",
    "    tukey_df = pd.DataFrame(\n",
    "        data=tukey.summary().data[1:],\n",
    "        columns=tukey.summary().data[0]\n",
    "    )\n",
    "    tukey_df.to_csv(\n",
    "        os.path.join(OUTPUT_DIR, f\"tukey_{feature}.csv\"),\n",
    "        index=False\n",
    "    )\n",
    "\n",
    "# ============================\n",
    "# ANOVA VISUALIZATION (BOXPLOTS)\n",
    "# ============================\n",
    "print(\"\\nGenerating ANOVA visualization images...\")\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "for feature in FEATURES:\n",
    "    plt.figure(figsize=(7,5))\n",
    "    sns.boxplot(\n",
    "        x=\"Class_Name\",\n",
    "        y=feature,\n",
    "        data=df,\n",
    "        palette=\"Set2\"\n",
    "    )\n",
    "    plt.title(f\"ANOVA Result ‚Äî {feature}\")\n",
    "    plt.xlabel(\"Drying Condition\")\n",
    "    plt.ylabel(feature)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\n",
    "        os.path.join(OUTPUT_DIR, f\"anova_boxplot_{feature}.png\"),\n",
    "        dpi=300\n",
    "    )\n",
    "    plt.close()\n",
    "\n",
    "print(\"\\nSTEP 8 completed successfully.\")\n",
    "print(\"All results and images saved in:\")\n",
    "print(OUTPUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c91b8550-1341-40e0-bd61-cdb50259911d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully\n",
      "Shape: (24084, 7)\n",
      "\n",
      "============================================================\n",
      "STEP 8 ‚Äî ONE-WAY ANOVA RESULTS\n",
      "============================================================\n",
      "R: F = 29983.3792, p = 0.000000e+00\n",
      "H_hsv: F = 7137.3116, p = 0.000000e+00\n",
      "Contrast: F = 1045.6462, p = 0.000000e+00\n",
      "Correlation: F = 665.7887, p = 3.655790e-282\n",
      "Energy: F = 692.7998, p = 2.875354e-293\n",
      "\n",
      "============================================================\n",
      "TUKEY HSD POST-HOC RESULTS\n",
      "============================================================\n",
      "\n",
      "Tukey results for R\n",
      "           Multiple Comparison of Means - Tukey HSD, FWER=0.05            \n",
      "==========================================================================\n",
      "     group1          group2      meandiff p-adj   lower     upper   reject\n",
      "--------------------------------------------------------------------------\n",
      "      Overdried Perfectly Dried  -93.4961   0.0  -94.5884  -92.4038   True\n",
      "      Overdried      Underdried -103.4146   0.0 -104.5068 -102.3223   True\n",
      "Perfectly Dried      Underdried   -9.9185   0.0  -11.0107   -8.8262   True\n",
      "--------------------------------------------------------------------------\n",
      "\n",
      "Tukey results for H_hsv\n",
      "          Multiple Comparison of Means - Tukey HSD, FWER=0.05          \n",
      "=======================================================================\n",
      "     group1          group2     meandiff p-adj  lower    upper   reject\n",
      "-----------------------------------------------------------------------\n",
      "      Overdried Perfectly Dried -49.7869   0.0 -50.8149  -48.759   True\n",
      "      Overdried      Underdried -39.0471   0.0  -40.075 -38.0191   True\n",
      "Perfectly Dried      Underdried  10.7399   0.0   9.7119  11.7679   True\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "Tukey results for Contrast\n",
      "          Multiple Comparison of Means - Tukey HSD, FWER=0.05          \n",
      "=======================================================================\n",
      "     group1          group2     meandiff p-adj  lower    upper   reject\n",
      "-----------------------------------------------------------------------\n",
      "      Overdried Perfectly Dried -16.0332   0.0 -20.6463 -11.4202   True\n",
      "      Overdried      Underdried  68.6834   0.0  64.0703  73.2965   True\n",
      "Perfectly Dried      Underdried  84.7166   0.0  80.1036  89.3297   True\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "Tukey results for Correlation\n",
      "         Multiple Comparison of Means - Tukey HSD, FWER=0.05         \n",
      "=====================================================================\n",
      "     group1          group2     meandiff p-adj  lower   upper  reject\n",
      "---------------------------------------------------------------------\n",
      "      Overdried Perfectly Dried  -0.0593   0.0 -0.0633 -0.0554   True\n",
      "      Overdried      Underdried  -0.0448   0.0 -0.0488 -0.0408   True\n",
      "Perfectly Dried      Underdried   0.0145   0.0  0.0106  0.0185   True\n",
      "---------------------------------------------------------------------\n",
      "\n",
      "Tukey results for Energy\n",
      "         Multiple Comparison of Means - Tukey HSD, FWER=0.05         \n",
      "=====================================================================\n",
      "     group1          group2     meandiff p-adj  lower   upper  reject\n",
      "---------------------------------------------------------------------\n",
      "      Overdried Perfectly Dried  -0.0076   0.0 -0.0089 -0.0062   True\n",
      "      Overdried      Underdried  -0.0208   0.0 -0.0222 -0.0195   True\n",
      "Perfectly Dried      Underdried  -0.0133   0.0 -0.0146 -0.0119   True\n",
      "---------------------------------------------------------------------\n",
      "\n",
      "STEP 8 completed successfully.\n",
      "All results and images saved in:\n",
      "C:\\Users\\Acer\\Downloads\\FINAL PROJECT\\STEP_8_ANOVA_RESULTS\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# STEP 8 ‚Äî ONE-WAY ANOVA + TUKEY HSD + IMAGE OUTPUTS\n",
    "# =========================================================\n",
    "\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "import os\n",
    "\n",
    "# ============================\n",
    "# CONFIGURATION\n",
    "# ============================\n",
    "DATA_PATH = r\"C:\\Users\\Acer\\Downloads\\FINAL PROJECT\\reduced_features_SMOTE_8028.csv\"\n",
    "OUTPUT_DIR = r\"C:\\Users\\Acer\\Downloads\\FINAL PROJECT\\STEP_8_ANOVA_RESULTS\"\n",
    "\n",
    "FEATURES = [\"R\", \"H_hsv\", \"Contrast\", \"Correlation\", \"Energy\"]\n",
    "CLASS_COL = \"Class\"\n",
    "\n",
    "class_map = {\n",
    "    0: \"Underdried\",\n",
    "    1: \"Perfectly Dried\",\n",
    "    2: \"Overdried\"\n",
    "}\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# ============================\n",
    "# LOAD DATA\n",
    "# ============================\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "df[\"Class_Name\"] = df[CLASS_COL].map(class_map)\n",
    "\n",
    "print(\"Dataset loaded successfully\")\n",
    "print(\"Shape:\", df.shape)\n",
    "\n",
    "# ============================\n",
    "# ONE-WAY ANOVA\n",
    "# ============================\n",
    "anova_results = []\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 8 ‚Äî ONE-WAY ANOVA RESULTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for feature in FEATURES:\n",
    "    groups = [\n",
    "        df[df[CLASS_COL] == cls][feature]\n",
    "        for cls in sorted(df[CLASS_COL].unique())\n",
    "    ]\n",
    "\n",
    "    F_stat, p_value = stats.f_oneway(*groups)\n",
    "\n",
    "    anova_results.append([\n",
    "        feature,\n",
    "        f\"{F_stat:.2f}\",\n",
    "        f\"{p_value:.2e}\",\n",
    "        \"Reject H‚ÇÄ\"\n",
    "    ])\n",
    "\n",
    "    print(f\"{feature}: F = {F_stat:.4f}, p = {p_value:.6e}\")\n",
    "\n",
    "anova_df = pd.DataFrame(\n",
    "    anova_results,\n",
    "    columns=[\"Feature\", \"F-statistic\", \"p-value\", \"Decision\"]\n",
    ")\n",
    "\n",
    "# ============================\n",
    "# SAVE ANOVA TABLE AS IMAGE\n",
    "# ============================\n",
    "fig, ax = plt.subplots(figsize=(9, 3))\n",
    "ax.axis('off')\n",
    "\n",
    "anova_table = ax.table(\n",
    "    cellText=anova_df.values,\n",
    "    colLabels=anova_df.columns,\n",
    "    loc='center',\n",
    "    cellLoc='center'\n",
    ")\n",
    "\n",
    "anova_table.auto_set_font_size(False)\n",
    "anova_table.set_fontsize(11)\n",
    "anova_table.scale(1, 1.6)\n",
    "\n",
    "plt.title(\"One-Way ANOVA Summary Results\", pad=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    os.path.join(OUTPUT_DIR, \"anova_summary_table.png\"),\n",
    "    dpi=300,\n",
    "    bbox_inches=\"tight\"\n",
    ")\n",
    "plt.close()\n",
    "\n",
    "# ============================\n",
    "# TUKEY HSD + IMAGE TABLES\n",
    "# ============================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TUKEY HSD POST-HOC RESULTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for feature in FEATURES:\n",
    "    tukey = pairwise_tukeyhsd(\n",
    "        endog=df[feature],\n",
    "        groups=df[\"Class_Name\"],\n",
    "        alpha=0.05\n",
    "    )\n",
    "\n",
    "    print(f\"\\nTukey results for {feature}\")\n",
    "    print(tukey.summary())\n",
    "\n",
    "    tukey_df = pd.DataFrame(\n",
    "        data=tukey.summary().data[1:],\n",
    "        columns=tukey.summary().data[0]\n",
    "    )\n",
    "\n",
    "    # Save Tukey table as IMAGE\n",
    "    fig, ax = plt.subplots(figsize=(10, 3))\n",
    "    ax.axis('off')\n",
    "\n",
    "    table = ax.table(\n",
    "        cellText=tukey_df.values,\n",
    "        colLabels=tukey_df.columns,\n",
    "        loc='center',\n",
    "        cellLoc='center'\n",
    "    )\n",
    "\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(10)\n",
    "    table.scale(1, 1.6)\n",
    "\n",
    "    plt.title(f\"Tukey HSD Post-Hoc Results ‚Äî {feature}\", pad=20)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig(\n",
    "        os.path.join(OUTPUT_DIR, f\"tukey_{feature}.png\"),\n",
    "        dpi=300,\n",
    "        bbox_inches=\"tight\"\n",
    "    )\n",
    "    plt.close()\n",
    "\n",
    "# ============================\n",
    "# ANOVA VISUALIZATION (BOXPLOTS)\n",
    "# ============================\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "for feature in FEATURES:\n",
    "    plt.figure(figsize=(7,5))\n",
    "    sns.boxplot(\n",
    "        x=\"Class_Name\",\n",
    "        y=feature,\n",
    "        data=df,\n",
    "        palette=\"Set2\"\n",
    "    )\n",
    "    plt.title(f\"ANOVA Result ‚Äî {feature}\")\n",
    "    plt.xlabel(\"Drying Condition\")\n",
    "    plt.ylabel(feature)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\n",
    "        os.path.join(OUTPUT_DIR, f\"anova_boxplot_{feature}.png\"),\n",
    "        dpi=300\n",
    "    )\n",
    "    plt.close()\n",
    "\n",
    "print(\"\\nSTEP 8 completed successfully.\")\n",
    "print(\"All results and images saved in:\")\n",
    "print(OUTPUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a4e793cf-a68b-45d7-a970-114ecc3b09ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 3 completed successfully.\n",
      "Descriptive statistics and clear boxplots saved in:\n",
      "C:\\Users\\Acer\\Downloads\\FINAL PROJECT\\STEP_3_Descriptive_Statistics\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# STEP 3 ‚Äî DESCRIPTIVE STATISTICS (IMPROVED BOXPLOTS)\n",
    "# =========================================================\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# ============================\n",
    "# CONFIGURATION\n",
    "# ============================\n",
    "DATA_PATH = r\"C:\\Users\\Acer\\Downloads\\FINAL PROJECT\\reduced_features_SMOTE_8028.csv\"\n",
    "OUTPUT_DIR = r\"C:\\Users\\Acer\\Downloads\\FINAL PROJECT\\STEP_3_Descriptive_Statistics\"\n",
    "\n",
    "FEATURES = [\"R\", \"H_hsv\", \"Contrast\", \"Correlation\", \"Energy\"]\n",
    "CLASS_COL = \"Class\"\n",
    "\n",
    "class_map = {\n",
    "    0: \"Underdried\",\n",
    "    1: \"Perfectly Dried\",\n",
    "    2: \"Overdried\"\n",
    "}\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# ============================\n",
    "# LOAD DATA\n",
    "# ============================\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "df[\"Class_Name\"] = df[CLASS_COL].map(class_map)\n",
    "\n",
    "# ============================\n",
    "# DESCRIPTIVE STATISTICS\n",
    "# ============================\n",
    "desc_stats = df.groupby(\"Class_Name\")[FEATURES].describe()\n",
    "desc_stats.to_csv(os.path.join(OUTPUT_DIR, \"descriptive_statistics_by_class.csv\"))\n",
    "\n",
    "# ============================\n",
    "# CLEAR BOXPLOTS\n",
    "# ============================\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "for feature in FEATURES:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "\n",
    "    sns.boxplot(\n",
    "        x=\"Class_Name\",\n",
    "        y=feature,\n",
    "        data=df,\n",
    "        width=0.5,\n",
    "        showfliers=False,          # üî¥ Makes box visible\n",
    "        linewidth=2,               # üî¥ Thicker box lines\n",
    "        palette=\"Set2\"\n",
    "    )\n",
    "\n",
    "    plt.title(f\"Boxplot of {feature} by Drying Class\", fontsize=14)\n",
    "    plt.xlabel(\"Drying Class\", fontsize=12)\n",
    "    plt.ylabel(feature, fontsize=12)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\n",
    "        os.path.join(OUTPUT_DIR, f\"boxplot_{feature}.png\"),\n",
    "        dpi=300\n",
    "    )\n",
    "    plt.close()\n",
    "\n",
    "print(\"STEP 3 completed successfully.\")\n",
    "print(\"Descriptive statistics and clear boxplots saved in:\")\n",
    "print(OUTPUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41dff80-4182-4855-930f-ecb5d6998cb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
